"""
This script evaluates the performance of a Variational Autoencoder (VAE) by comparing real images with generated images using three metrics: SSIM, LPIPS, and FID.
Classes:
    ImageDataset: A custom dataset class for loading and transforming real and generated images.
Functions:
    calculate_ssim(real_img, gen_img):
        Calculates the Structural Similarity Index (SSIM) between two images.
    calculate_fid(real_features, gen_features):
        Calculates the Frechet Inception Distance (FID) between two sets of features.
    get_inception_features(images, model):
        Extracts features from images using a pre-trained Inception v3 model.
    evaluate_vae(real_dir, gen_dir, batch_size, device):
        Evaluates the VAE by calculating SSIM, LPIPS, and FID scores for real and generated images.
Usage:
    The script can be run as a standalone program. It reads images from specified directories, evaluates the VAE, and prints the SSIM, LPIPS, and FID scores.
Example:
    input_folder = "/path/to/real/images"
    output_folder = "/path/to/generated/images"
"""
import os
import numpy as np
import torch
from PIL import Image
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from skimage.metrics import structural_similarity as ssim
import lpips
from scipy.linalg import sqrtm
import argparse

class ImageDataset(Dataset):
    def __init__(self, real_images, generated_images):
        self.transform = transforms.Compose([transforms.Grayscale(num_output_channels=3),transforms.ToTensor()])
        self.real = real_images
        self.gen = generated_images

    def __len__(self):
        return len(self.real)

    def __getitem__(self, idx):
        real_img = Image.open(self.real[idx])
        gen_img = Image.open(self.gen[idx])
        # real_img = torch.from_numpy(real_img).permute(2, 0, 1)
        # gen_img = torch.from_numpy(gen_img).permute(2, 0, 1)
        return self.transform(real_img), self.transform(gen_img)

def calculate_ssim(real_np, gen_np):
    # real_np, gen_np: numpy arrays, shape (H, W, C) or (C, H, W)
    # 如果是 (C, H, W)，需要转为 (H, W, C)
    real_np = real_np.cpu().numpy()
    gen_np = gen_np.cpu().numpy()
    if real_np.shape[0] == 3:
        real_np = real_np.transpose(1, 2, 0)
        gen_np = gen_np.transpose(1, 2, 0)
    return ssim(
        real_np, gen_np,
        channel_axis=-1,   # 指定通道轴
        win_size=7,        # 或更小的奇数（如5），确保小于等于最小边
        data_range=real_np.max() - real_np.min()
    )

def calculate_fid(real_features, gen_features):
    if len(real_features.shape) > 2:
        real_features = real_features.reshape(real_features.shape[0], -1)
        gen_features = gen_features.reshape(gen_features.shape[0], -1)
    
    mu1 = np.mean(real_features, axis=0)
    sigma1 = np.cov(real_features, rowvar=False)
    mu2 = np.mean(gen_features, axis=0)
    sigma2 = np.cov(gen_features, rowvar=False)

    ssdiff = np.sum((mu1 - mu2) ** 2.0)
    
    try:
        covmean = sqrtm(sigma1.dot(sigma2))
        if np.iscomplexobj(covmean):
            covmean = covmean.real
        fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)
    except ValueError:
        fid = float('inf')
    
    return fid

def get_inception_features(images, model):
    with torch.no_grad():
        features = model(images)[0]
    return features.squeeze(-1).squeeze(-1).cpu().numpy()

def evaluate_vae(real_dir, gen_dir, batch_size, device):
    dataset = ImageDataset(real_dir, gen_dir)
    loader = DataLoader(dataset, batch_size=batch_size)
    
    ssim_scores = []
    lpips_scores = []
    real_features = []
    gen_features = []
    
    loss_fn_alex = lpips.LPIPS(net='alex').to(device)
    inception_model = models.inception_v3(pretrained=True, aux_logits=True).to(device)
    inception_model.eval()
    
    for real_batch, gen_batch in loader:
        real_batch = real_batch.to(device)
        gen_batch = gen_batch.to(device)
        
        for r, g in zip(real_batch, gen_batch):
            ssim_scores.append(calculate_ssim(r, g))
        
        lpips_val = loss_fn_alex(real_batch, gen_batch)
        lpips_scores.extend(lpips_val.cpu().numpy())
        
        real_features.append(get_inception_features(real_batch, inception_model))
        gen_features.append(get_inception_features(gen_batch, inception_model))
    
    real_features = np.concatenate(real_features)
    gen_features = np.concatenate(gen_features)
    fid_score = calculate_fid(real_features, gen_features)
    
    return {
        'SSIM': np.mean(ssim_scores),
        'LPIPS': np.mean(lpips_scores),
        'FID': fid_score
    }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Eval images generated by a trained VAE model.")
    # parser.add_argument("-m", "--model", type=str, help="Path to the trained VAE model.")
    parser.add_argument("-real_data_path", "--input", type=str, help="Path to the input folder.")
    parser.add_argument("-fake_data_path", "--output", type=str, help="Path to the output folder.")
    parser.add_argument("-b", "--batch_size", type=int, default=128, help="Batch size to use for encoding and decoding.")

    args = parser.parse_args()

    input_folder = os.path.abspath(args.input)
    output_folder = os.path.abspath(args.output)
    image_names = os.listdir(input_folder)
    real_images = [os.path.join(input_folder, i) for i in image_names]
    generated_images = [os.path.join(output_folder, i) for i in image_names]
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    batch_size = args.batch_size
    
    torch.set_grad_enabled(False)
    metrics = evaluate_vae(real_images, generated_images, batch_size, device)
    print(f"SSIM: {metrics['SSIM']:.4f}")
    print(f"LPIPS: {metrics['LPIPS']:.4f}")
    print(f"FID: {metrics['FID']:.2f}")
